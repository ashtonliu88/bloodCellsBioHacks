{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rFvmC_TN6uq",
        "outputId": "3f04c944-cb4c-4c15-8f59-0438a1da9876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shotomorisaki/Engineering/bloodCellsBioHacks/notebook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vbookshelf/respiratory-sound-database?dataset_version_number=2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/3.69G [00:00<?, ?B/s]"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"vbookshelf/respiratory-sound-database\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm7xRNYGPula"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M_z3E-Y4N82o",
        "outputId": "81aead5f-307d-48ae-a7d7-ef58f53014be"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'librosa'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract spectrogram from audio\n",
        "def extract_spectrogram(audio_path, n_mels=128, fmax=8000):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=None)  # Load the audio file\n",
        "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)  # Compute Mel spectrogram\n",
        "        log_S = librosa.power_to_db(S, ref=np.max)  # Convert to decibel scale\n",
        "        return log_S\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to extract MFCCs from audio\n",
        "def extract_mfcc(audio_path, n_mfcc=13):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, sr=None)  # Load the audio file\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)  # Compute MFCCs\n",
        "        return mfccs\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to process all audio files in a given directory\n",
        "def process_audio_files(dataset_path, extension='.wav', batch_size=10):\n",
        "    audio_files = glob.glob(os.path.join(dataset_path, f'**/*{extension}'), recursive=True)  # Get all audio files recursively\n",
        "    spectrograms = []\n",
        "    mfccs = []\n",
        "    \n",
        "    # Process audio files in batches\n",
        "    for i, audio_path in enumerate(audio_files):\n",
        "        spectrogram = extract_spectrogram(audio_path)\n",
        "        mfcc = extract_mfcc(audio_path)\n",
        "        \n",
        "        if spectrogram is not None:\n",
        "            spectrograms.append(spectrogram)\n",
        "        if mfcc is not None:\n",
        "            mfccs.append(mfcc)\n",
        "        \n",
        "        # Process in batches to reduce memory usage\n",
        "        if len(spectrograms) >= batch_size:\n",
        "            print(f\"Processed {i + 1}/{len(audio_files)} files\")\n",
        "            break  # Optional: Remove this line if you want to process all files\n",
        "    \n",
        "    # Check if any spectrograms were generated\n",
        "    if not spectrograms:\n",
        "        print(\"No spectrograms were generated.\")\n",
        "    \n",
        "    return spectrograms, mfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/vbookshelf/respiratory-sound-database/versions/2/respiratory_sound_database/Respiratory_Sound_Database/audio_and_txt_files'\n",
        "\n",
        "# Get and print the list of files\n",
        "audio_files = glob.glob(os.path.join(dataset_path, '**/*.wav'), recursive=True)\n",
        "print(f\"Found {len(audio_files)} audio files.\")\n",
        "\n",
        "# Process a small batch of audio files\n",
        "spectrograms, mfccs = process_audio_files(dataset_path, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if we have valid data for training\n",
        "if spectrograms:\n",
        "    print(f\"Spectrograms shape: {np.array(spectrograms).shape}\")\n",
        "else:\n",
        "    print(\"No spectrograms to process.\")\n",
        "\n",
        "# Ensure there is data to proceed with\n",
        "if spectrograms:\n",
        "    # Visualize a sample spectrogram if available\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(spectrograms[0], aspect='auto', origin='lower', cmap='inferno')\n",
        "    plt.title('Spectrogram of First Audio File')\n",
        "    plt.xlabel('Time (Frames)')\n",
        "    plt.ylabel('Frequency Bins')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check MFCCs\n",
        "if mfccs:\n",
        "    print(f\"MFCCs shape: {np.array(mfccs).shape}\")\n",
        "else:\n",
        "    print(\"No MFCCs to process.\")\n",
        "    \n",
        "if mfccs:\n",
        "    # Visualize MFCCs if available\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(mfccs[0], aspect='auto', origin='lower', cmap='viridis')\n",
        "    plt.title('MFCCs of First Audio File')\n",
        "    plt.xlabel('Time (Frames)')\n",
        "    plt.ylabel('MFCC Coefficients')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Developing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to preprocess data\n",
        "def preprocess_data(spectrograms, labels):\n",
        "    if len(spectrograms) == 0:\n",
        "        raise ValueError(\"No valid spectrograms to preprocess.\")\n",
        "    \n",
        "    spectrograms = np.array(spectrograms)\n",
        "    max_vals = np.max(spectrograms, axis=(1, 2), keepdims=True)\n",
        "    spectrograms = spectrograms / (max_vals + 1e-10)\n",
        "    \n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(labels)\n",
        "    \n",
        "    # Reshape for CNN input: (samples, height, width, channels)\n",
        "    spectrograms = spectrograms.reshape(spectrograms.shape[0], spectrograms.shape[1], spectrograms.shape[2], 1)\n",
        "    return spectrograms, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RandomForest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(file_path, sr=22050, n_mfcc=13):\n",
        "    \"\"\"\n",
        "    Extract audio features including MFCCs, spectral centroid,\n",
        "    zero crossing rate, spectral bandwidth, and chroma features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=sr)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "    \n",
        "    if y.size == 0:\n",
        "        print(f\"File {file_path} is empty.\")\n",
        "        return None\n",
        "\n",
        "    # MFCCs\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "    # Spectral centroid\n",
        "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "    spec_centroid_mean = np.mean(spec_centroid)\n",
        "    spec_centroid_std = np.std(spec_centroid)\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    zcr_mean = np.mean(zcr)\n",
        "    zcr_std = np.std(zcr)\n",
        "\n",
        "    # Spectral bandwidth\n",
        "    spec_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    spec_bandwidth_mean = np.mean(spec_bandwidth)\n",
        "    spec_bandwidth_std = np.std(spec_bandwidth)\n",
        "\n",
        "    # Chroma features\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    chroma_mean = np.mean(chroma, axis=1)\n",
        "    chroma_std = np.std(chroma, axis=1)\n",
        "\n",
        "    # Combine features into a dictionary\n",
        "    features = {}\n",
        "    for i in range(n_mfcc):\n",
        "        features[f'mfcc_{i+1}_mean'] = mfcc_mean[i]\n",
        "        features[f'mfcc_{i+1}_std'] = mfcc_std[i]\n",
        "    \n",
        "    features['spec_centroid_mean'] = spec_centroid_mean\n",
        "    features['spec_centroid_std'] = spec_centroid_std\n",
        "    features['zcr_mean'] = zcr_mean\n",
        "    features['zcr_std'] = zcr_std\n",
        "    features['spec_bandwidth_mean'] = spec_bandwidth_mean\n",
        "    features['spec_bandwidth_std'] = spec_bandwidth_std\n",
        "    \n",
        "    for i in range(chroma.shape[0]):\n",
        "        features[f'chroma_{i+1}_mean'] = chroma_mean[i]\n",
        "        features[f'chroma_{i+1}_std'] = chroma_std[i]\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_files = glob.glob(os.path.join(dataset_path, '**/*.wav'), recursive=True)\n",
        "print(f\"Found {len(audio_files)} audio files.\")\n",
        "\n",
        "feature_list = []\n",
        "labels = []\n",
        "\n",
        "# Loop over files and extract features with updated label extraction\n",
        "for file in audio_files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "    feats = extract_features(file)\n",
        "    if feats is None:\n",
        "        print(f\"Skipping file due to extraction error: {file}\")\n",
        "        continue\n",
        "    feature_list.append(feats)\n",
        "    \n",
        "    # Extract label from the file name.\n",
        "    file_name = os.path.basename(file)\n",
        "    parts = file_name.split('_')\n",
        "    if len(parts) >= 3:\n",
        "        code = parts[2]\n",
        "        # Map codes to labels. Adjust these mappings as needed.\n",
        "        if code in ['Ar', 'Lr']:\n",
        "            label = 'healthy'\n",
        "        elif code == 'Tc':\n",
        "            label = 'diseased'\n",
        "        else:\n",
        "            label = 'unknown'\n",
        "    else:\n",
        "        label = 'unknown'\n",
        "    \n",
        "    labels.append(label)\n",
        "    # print(f\"Extracted label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame from features and labels\n",
        "df_features = pd.DataFrame(feature_list)\n",
        "df_features['label'] = labels\n",
        "\n",
        "# Optionally, filter out rows if you have unwanted labels (adjust if necessary)\n",
        "# For example, if you only expect 'healthy' and 'diseased' labels:\n",
        "df_features = df_features[df_features['label'].isin(['healthy', 'diseased'])]\n",
        "\n",
        "print(\"Feature DataFrame shape:\", df_features.shape)\n",
        "print(df_features.head())\n",
        "\n",
        "# Separate features and target labels\n",
        "X = df_features.drop(\"label\", axis=1)\n",
        "y = df_features['label']\n",
        "\n",
        "# Encode string labels to integers (binary classification)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the classifier\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Set the style\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Create the bar plot\n",
        "bars = ax.bar(range(len(importances)), \n",
        "              importances[indices],\n",
        "              color=sns.color_palette(\"Blues_r\", len(importances)),\n",
        "              align=\"center\")\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_title(\"Feature Importances\", fontsize=14, pad=20)\n",
        "ax.set_xlabel(\"Features\", fontsize=12, labelpad=10)\n",
        "ax.set_ylabel(\"Importance Score\", fontsize=12, labelpad=10)\n",
        "\n",
        "# Customize x-axis\n",
        "ax.set_xticks(range(len(importances)))\n",
        "ax.set_xticklabels(features[indices], rotation=45, ha='right')\n",
        "ax.set_xlim([-0.5, len(importances)-0.5])\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    # ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "    #         f'{height:.3f}',\n",
        "    #         ha='center', va='bottom')\n",
        "\n",
        "# Add grid for better readability\n",
        "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
